{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-3896c6810337>:97: softmax_cross_entropy (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.\n",
      "Instructions for updating:\n",
      "Use tf.losses.softmax_cross_entropy instead. Note that the order of the logits and labels arguments has been changed.\n",
      "WARNING:tensorflow:From C:\\Users\\Sand3r\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\losses\\python\\losses\\loss_ops.py:398: compute_weighted_loss (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.\n",
      "Instructions for updating:\n",
      "Use tf.losses.compute_weighted_loss instead.\n",
      "WARNING:tensorflow:From C:\\Users\\Sand3r\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\losses\\python\\losses\\loss_ops.py:151: add_arg_scope.<locals>.func_with_args (from tensorflow.contrib.framework.python.ops.arg_scope) is deprecated and will be removed after 2016-12-30.\n",
      "Instructions for updating:\n",
      "Use tf.losses.add_loss instead.\n",
      "WARNING:tensorflow:From <ipython-input-1-3896c6810337>:98: get_total_loss (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.\n",
      "Instructions for updating:\n",
      "Use tf.losses.get_total_loss instead.\n",
      "WARNING:tensorflow:From C:\\Users\\Sand3r\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\losses\\python\\losses\\loss_ops.py:261: get_losses (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.\n",
      "Instructions for updating:\n",
      "Use tf.losses.get_losses instead.\n",
      "WARNING:tensorflow:From C:\\Users\\Sand3r\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\losses\\python\\losses\\loss_ops.py:263: get_regularization_losses (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.\n",
      "Instructions for updating:\n",
      "Use tf.losses.get_regularization_losses instead.\n",
      "Number of trainable parameters 2154420\n",
      "Loading checkpoint from train_aws/model.ckpt-98055\n",
      "INFO:tensorflow:Restoring parameters from train\\model.ckpt-1419\n",
      "INFO:tensorflow:Starting Session.\n",
      "INFO:tensorflow:Saving checkpoint to path train\\model.ckpt\n",
      "INFO:tensorflow:Starting Queues.\n",
      "INFO:tensorflow:global_step/sec: 0\n",
      "INFO:tensorflow:Recording summary at step 1419.\n",
      "INFO:tensorflow:global_step/sec: 0\n",
      "INFO:tensorflow:Recording summary at step 1420.\n",
      "INFO:tensorflow:global_step/sec: 0.0333603\n",
      "INFO:tensorflow:Recording summary at step 1420.\n",
      "INFO:tensorflow:global_step/sec: 0.0333403\n",
      "INFO:tensorflow:Recording summary at step 1421.\n",
      "INFO:tensorflow:global_step/sec: 0.0333059\n",
      "INFO:tensorflow:Recording summary at step 1422.\n",
      "INFO:tensorflow:global_step/sec: 0.0333292\n",
      "INFO:tensorflow:Recording summary at step 1423.\n",
      "INFO:tensorflow:global_step/sec: 0.0333292\n",
      "INFO:tensorflow:Recording summary at step 1424.\n",
      "INFO:tensorflow:global_step/sec: 0.0333603\n",
      "INFO:tensorflow:Recording summary at step 1425.\n",
      "INFO:tensorflow:global_step/sec: 0.0333225\n",
      "INFO:tensorflow:Recording summary at step 1426.\n",
      "INFO:tensorflow:global_step/sec: 0.0333574\n",
      "INFO:tensorflow:Recording summary at step 1427.\n",
      "INFO:tensorflow:Saving checkpoint to path train\\model.ckpt\n",
      "INFO:tensorflow:Recording summary at step 1428.\n",
      "INFO:tensorflow:Recording summary at step 1429.\n",
      "INFO:tensorflow:Recording summary at step 1430.\n",
      "INFO:tensorflow:Recording summary at step 1431.\n",
      "INFO:tensorflow:Recording summary at step 1432.\n",
      "INFO:tensorflow:Recording summary at step 1433.\n",
      "INFO:tensorflow:Recording summary at step 1434.\n",
      "INFO:tensorflow:Recording summary at step 1435.\n",
      "INFO:tensorflow:Recording summary at step 1436.\n",
      "INFO:tensorflow:Recording summary at step 1437.\n",
      "INFO:tensorflow:Saving checkpoint to path train\\model.ckpt\n",
      "INFO:tensorflow:Recording summary at step 1438.\n",
      "INFO:tensorflow:Recording summary at step 1439.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-3896c6810337>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0msave_summaries_secs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0mlog_every_n_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             init_fn=InitAssignFn)\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Sand3r\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\slim\\python\\slim\\learning.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_op, logdir, train_step_fn, train_step_kwargs, log_every_n_steps, graph, master, is_chief, global_step, number_of_steps, init_op, init_feed_dict, local_init_op, init_fn, ready_op, summary_op, save_summaries_secs, summary_writer, startup_delay_steps, saver, save_interval_secs, sync_optimizer, session_config, trace_every_n_steps)\u001b[0m\n\u001b[1;32m    753\u001b[0m           \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m             total_loss, should_stop = train_step_fn(\n\u001b[0;32m--> 755\u001b[0;31m                 sess, train_op, global_step, train_step_kwargs)\n\u001b[0m\u001b[1;32m    756\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mshould_stop\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m               \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Stopping Training.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Sand3r\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\slim\\python\\slim\\learning.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(sess, train_op, global_step, train_step_kwargs)\u001b[0m\n\u001b[1;32m    486\u001b[0m   total_loss, np_global_step = sess.run([train_op, global_step],\n\u001b[1;32m    487\u001b[0m                                         \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrace_run_options\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 488\u001b[0;31m                                         run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    489\u001b[0m   \u001b[0mtime_elapsed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Sand3r\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Sand3r\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Sand3r\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Sand3r\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Sand3r\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import io as imp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import tensorflow as tf\n",
    "from network import net\n",
    "import json\n",
    "from data_utils import *\n",
    "slim = tf.contrib.slim\n",
    "# This might increase training time, so set to False if desired\n",
    "image_in_tensorboard = True\n",
    "batch_size, height, width, nchannels = 3, 360, 480, 3\n",
    "final_resized = 224\n",
    "learning_rate = 0.001\n",
    "model_version = 56\n",
    "USE_AWS_WEIGHTS=True\n",
    "\n",
    "# Remap colours\n",
    "_cmap = [(128, 128, 128), (128, 0, 0), (192, 192, 128), (128, 64, 128), (0, 0, 192), (128, 128, 0), (192, 128, 128), (64, 64, 128), (64, 0, 128), (64, 64, 0), (0, 128, 192), (0, 0, 0)]\n",
    "_mask_labels = {0: 'sky', 1: 'building', 2: 'column_pole', 3: 'road',\n",
    "                    4: 'sidewalk', 5: 'tree', 6: 'sign', 7: 'fence', 8: 'car',\n",
    "                    9: 'pedestrian', 10: 'byciclist', 11: 'void'}\n",
    "\n",
    "def colorize(grayimg):\n",
    "    gray_int=tf.cast(grayimg, tf.int32) # Cast to integer to allow to function as index\n",
    "    gray_remapped=tf.gather(_cmap, gray_int) # Map gray to rgb\n",
    "    gray_sq = tf.squeeze(gray_remapped) # Remove the dimension of 1\n",
    "    return tf.cast(gray_sq, tf.float32) # Return as a float\n",
    "\n",
    "# Legend\n",
    "def legend():\n",
    "    blocksize=0.1\n",
    "    plt.figure(figsize=(5, 3))\n",
    "    for i in range(len(_cmap)):\n",
    "        xoffset=0\n",
    "        yoffset=0\n",
    "        if(i>5):\n",
    "            xoffset=0.5\n",
    "            yoffset=6*blocksize\n",
    "        clr=(_cmap[i][0]/255,_cmap[i][1]/255,_cmap[i][2]/255)\n",
    "        square = plt.Rectangle((0+xoffset, i*0.1-yoffset), width=blocksize, height=blocksize, fc=clr)\n",
    "        plt.text(0.2+xoffset, 0.03+i*0.1-yoffset, _mask_labels[i], fontsize=10)\n",
    "        plt.gca().add_patch(square)\n",
    "    plt.ylim([0,0.6])\n",
    "    plt.axis('off')\n",
    "    buf = imp.BytesIO()\n",
    "    plt.savefig(buf, format='png')\n",
    "    buf.seek(0)\n",
    "    return buf\n",
    "\n",
    "buffer = legend()\n",
    "# To TF image\n",
    "legend = tf.image.decode_png(buffer.getvalue(), channels=4)\n",
    "legend = tf.expand_dims(legend, 0)\n",
    "\n",
    "\n",
    "\n",
    "with open('model_parameters.json') as params:\n",
    "    params_dict = json.load(params)[repr(model_version)]\n",
    "\n",
    "params_dict['input_num_features'] = 48\n",
    "# params_dict['input_num_features'] = 16\n",
    "params_dict['output_classes'] = 12\n",
    "\n",
    "# Save training data in tfrec and load it into a slim dataset\n",
    "\n",
    "tfrec_dump(train_paths, \"trainset.tfrec\")\n",
    "tfsdataset = slim_dataset(\"trainset.tfrec\", 367)\n",
    "\n",
    "\n",
    "gpu_opts = tf.GPUOptions(per_process_gpu_memory_fraction=0.9)\n",
    "# Training loop\n",
    "with tf.Session(config=tf.ConfigProto(gpu_options=gpu_opts)) as sess:\n",
    "    log_dir = 'train'\n",
    "    # We load a batch and reshape to tensor\n",
    "    xbatch, ybatch = batch(\n",
    "        tfsdataset, batch_size=batch_size, height=height, width=width, resized=final_resized)\n",
    "    input_batch = tf.reshape(xbatch, shape=(\n",
    "        batch_size, final_resized, final_resized, 3))\n",
    "    ground_truth_batch = tf.reshape(ybatch, shape=(\n",
    "        batch_size, final_resized, final_resized, 1))\n",
    "\n",
    "    # Obtain the prediction\n",
    "    predictions = net(input_batch, params_dict)\n",
    "\n",
    "    # We calculate the loss\n",
    "    one_hot_labels = slim.one_hot_encoding(\n",
    "        tf.squeeze(ground_truth_batch),\n",
    "        params_dict['output_classes'])\n",
    "\n",
    "    masked_weights = 1 - tf.unstack(one_hot_labels, axis=-1)[-1]\n",
    "\n",
    "    slim.losses.softmax_cross_entropy(\n",
    "        predictions,\n",
    "        one_hot_labels,\n",
    "        weights=masked_weights)\n",
    "    total_loss = slim.losses.get_total_loss()\n",
    "    tf.summary.scalar('loss', total_loss)\n",
    "\n",
    "    if (image_in_tensorboard):\n",
    "        yb = tf.cast(tf.divide(ground_truth_batch, 11), tf.float32)\n",
    "        tf.summary.image(\"y\", yb, max_outputs=1)\n",
    "\n",
    "        predim = tf.nn.softmax(predictions)\n",
    "        predimmax = tf.expand_dims(\n",
    "            tf.cast(tf.argmax(predim, axis=3), tf.float32), -1)\n",
    "        predimmaxdiv = tf.divide(tf.cast(predimmax, tf.float32), 11)\n",
    "        tf.summary.image(\"y_hat\", predimmaxdiv, max_outputs=1)\n",
    "\n",
    "        tf.summary.image(\"Mask\", tf.expand_dims(masked_weights, axis=-1), max_outputs=1)\n",
    "\n",
    "        ediff = tf.minimum(tf.abs(tf.subtract(yb, predimmaxdiv)), tf.expand_dims(masked_weights, axis=-1))\n",
    "        tf.summary.image(\"Error_difference\", ediff, max_outputs=1)\n",
    "\n",
    "        legend_sum = tf.summary.image(\"Legend\", legend)\n",
    "\n",
    "        tf.summary.image(\"Cy\", colorize(ground_truth_batch), max_outputs=1)\n",
    "        tf.summary.image(\"Cy_hat\", colorize(predimmax), max_outputs=1)\n",
    "\n",
    "        tf.summary.image(\"x\", input_batch, max_outputs=1)\n",
    "\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "    train_op = slim.learning.create_train_op(\n",
    "        total_loss, optimizer, summarize_gradients=False)\n",
    "    print(\"Number of trainable parameters\", np.sum(\n",
    "        [np.prod(v.shape) for v in tf.trainable_variables()]))\n",
    "    if USE_AWS_WEIGHTS:\n",
    "        checkpoint_path = 'train_aws/model.ckpt-98055'\n",
    "        print(\"Loading checkpoint from \" + checkpoint_path)\n",
    "        variables_to_restore = slim.get_model_variables()\n",
    "        init_assign_op, init_feed_dict = slim.assign_from_checkpoint(\n",
    "          checkpoint_path, variables_to_restore)\n",
    "        def InitAssignFn(sess):\n",
    "            sess.run(init_assign_op, init_feed_dict)\n",
    "        final_loss = slim.learning.train(\n",
    "            train_op, logdir=log_dir,\n",
    "            save_interval_secs=300,\n",
    "            save_summaries_secs=30,\n",
    "            log_every_n_steps=100,\n",
    "            init_fn=InitAssignFn)\n",
    "\n",
    "    else:\n",
    "        final_loss = slim.learning.train(\n",
    "            train_op, logdir=log_dir,\n",
    "            save_interval_secs=300,\n",
    "            save_summaries_secs=30,\n",
    "            log_every_n_steps=100)\n",
    "\n",
    "print(\"Done. With final loss: %s\" % final_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
